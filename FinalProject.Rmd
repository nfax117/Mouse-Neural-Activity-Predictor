---
title: "STA 141A Final Project: Predictive Model of Mice Neural Activity"
author: "Nathaniel Faxon 917100572"
date: "2023-06-12"
output: html_document
abstract: |
  In this project, we were given 18 sessions of mice brain neural activity, each session recording brain activity related variables as well as the feedback produced from the mice after completing a visual discrimination task. With this information, data was combined into one complete dataframe and important variables were classified. Clustering and classification techniques were used in order to identify similar data across different trials. Logistic, Tree-Based, and SVM prediction regression methods were then applied to the complete dataframe that holds our predicting variabes in order to form our predictive model.
---

```{r, echo=FALSE, warning=FALSE, results='hide',include = FALSE, message=FALSE}
# Load the relevant libraries

suppressWarnings(library(tidyverse))
suppressWarnings(library(ggplot2))
suppressWarnings(library(knitr))
suppressWarnings(library(dplyr))
suppressWarnings(library(gtools))
suppressWarnings(library(corrplot))
suppressWarnings(library(gridExtra))
suppressWarnings(library(grid))
suppressWarnings(library(PerformanceAnalytics))
suppressWarnings(library(grDevices))
suppressWarnings(library(viridis))
suppressWarnings(library(RColorBrewer))
suppressWarnings(library(reshape2))
suppressWarnings(library(ggcorrplot))
suppressWarnings(library(DT))
suppressWarnings(library(glmnet))
suppressWarnings(library(MASS))
suppressWarnings(library(caret))
suppressWarnings(library(class))
suppressWarnings(library(tree))
suppressWarnings(library(rpart))
suppressWarnings(library(e1071))
suppressWarnings(library(magrittr))
suppressWarnings(library(formattable))

# Set seed
set.seed(777) 
```

## Introduction

        
In the original study, the neural activity of 30,000 neurons in 42 brain regions of mice were analyzed. There were 10 mice analyzed over 39 different sessions. Within each session, visual stimuli were presented to the mice at random, then the reaction of the mice to this stimuli were recorded.

In this project, we will be analyzing the different trials and recorded neuron spikes in order to make a predictive model for feedback type. This research is important because it can help one understand the different brain regions that participate in action selection. Past studies about action selection tended to focus on individual brain region. This study could help explain how other regions like, sensory regions, could also participate in action selection. In the end, this study provides the organizing principles for the distribution of how neurons encode behavioral relevant variables in the brain of a mouse.

The 18 different session that we will be analyzing comes in the form of RDS files. The data comes from 18 different session of 4 different mice brain neural activity. The four mice that we are studying the neural responses of are Cori, Forssmann, Hench, and Lederberg. More specifically, the first three sessions analyzed Cori, the next four Forssmann, the next four Hench, and the last seven Lederberg. These sessions were taken between 12/14/2016 through 12/11/2017.

Within each session, there were many trials where the activity of the neurons in the mice's visual cortex was recorded based on their decision making when faced with visual stimuli. Their decision making consists of turning the wheel either to the left or right or holding it still. Different variables were recorded for the 4 different mice. 8 variables are recorded each session:

-   brain_area: The area of the brain where each neuron lives.
-   contrast_left: Contrast on the left stimulus. Can take values 0, 0.25, 0.5, 1 (0 indicating the absence of a stimulus).
-   contrast_right: Contrast on the right stimulus. Can take values 0, 0.25, 0.5, 1 (0 indicating the absence of a stimulus).
-   date_exp: Date of the experiment on the mouse.
-   feedback_type: The type of feedback that was administered base on the outcome of the mouse's decision. There are four different cases that can happen:
    -   When the right contrast is greater than the left contrast: If the mouse turned the wheel to the left, feedback_type = 1. If turned to the right, feedback_type = -1.
    -   When the left contrast is greater than the right contrast: If the mouse turned the wheel to the right, feedback_type = 1. If turned to the left, feedback_type = -1.
    -   When the left contrast and right contrast equal 0: If mouse held the wheel still, feedback_type = 1. Otherwise, feedback_type = -1.
    -   When the left contrast and right contrast are equal and not both 0: There is a 50% chance that feedback_type = 1 or -1.
-   mouse_name: Name of the mouse being used in the experiment (trial). Specific to this project, the 4 mice are Cori, Forssmann, Hench, and Lederberg.
-   spks: Numbers of spikes of neurons in the visual cortex. Holds many different trials.
-   time: Center of the time bins for the spks.

From the existing research, neuron patterns within the mice have emerged when responding to their visual discrimination task. Specific areas within their brain are occupied when the neurons encode visual stimuli. But in completing the overall task, all brain areas had pre-stimulus activity with enhanced subcortical and suppressed neocortical activity during engagement.


## Descriptive Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Load the session information

session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('./Data/session',i,'.rds',sep=''))
  #print(session[[i]]$mouse_name)
  #print(session[[i]]$date_exp)
  
}

```

```{r, echo=FALSE, warning=FALSE, results='hide',include = FALSE, message=FALSE}

# Get the variables recorded within this session
print(ls(session[[1]])) # or names(session[[1]]))

#Determine the different variables and details within each session

uniqueBrainareasVector <- c()

for (i in 1:18) {
  
  message("Session ", i)
  
  session_i <- session[[i]]
  
  print(session[[i]]$mouse_name)
  print(session[[i]]$date_exp)
  
  # Get the affected brain areas within this session
  print("Affected brain areas:")
  print(unique(session_i$brain_area))
  
  uniqueBrainareasVector <- append(uniqueBrainareasVector, unique(session_i$brain_area))
  
  # Get the number of trials within the session
  print("Number of trials:")
  print(length(session_i$feedback_type))
  
}

# Get the unique brainareas through all sessions
uniqueBrainareasVector <- unique(uniqueBrainareasVector)
uniqueBrainareasVectorLength = length(uniqueBrainareasVector)
message("There are ", uniqueBrainareasVectorLength, " unique brain areas throughout all sessions:")
print(uniqueBrainareasVector)



```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Dataframe with general statistics across sessions

sessionDF <- data.frame()

for (i in 1:18) {

  #Create a custom dataframe here with 4 columns for 4 variables
  trialDF <- data.frame(matrix(ncol = 5, nrow = 0))

  for (j in 1:length(session[[i]]$spks)) { 
    
    # Calculate the total number of neurons active
    neuronCountTable = table(unlist(session[[i]]$spks[[j]]))
    neuronCountValues = as.numeric(neuronCountTable)
    numActiveNeurons = length(session[[i]]$spks[[j]]) - neuronCountValues[1] #neuronCountValues[1] is the # of 0's
    
    # Calculate the total number of spks
    numSpks = 0
    for(k in 1:length(neuronCountTable)) {
    
      numSpks = numSpks + ((k-1) * neuronCountValues[k])
      
    }
    
    # Calculate the proportion of active neurons
    activeNeuronProp = numActiveNeurons / length(session[[i]]$spks[[i]])
    
    # Calculate the firing rate (total number of spks != 0 divided by total)
    firing_rate = numSpks / (numSpks + neuronCountValues[1])
    
    # Calculate the absolute difference between left and right contrast
    contrastDifference = abs(session[[i]]$contrast_left[j] - session[[i]]$contrast_right[j])
    
    # Append to the variables to the trial data frame
    trialDF[nrow(trialDF) + 1,] = c(contrastDifference, numActiveNeurons, numSpks, activeNeuronProp, firing_rate)
    
  }
  
  # Append data together using cbind
  tempSession = cbind(rep(i,length(session[[i]]$contrast_left)),
                       seq(1, length(session[[i]]$spks)),
                       session[[i]]$mouse_name, 
                       session[[i]]$contrast_left,
                       session[[i]]$contrast_right,
                       length(session[[i]]$brain_area),
                       length(unique(session[[i]]$brain_area)),
                       length(session[[i]]$spks),
                       trialDF,
                       session[[i]]$feedback_type
                       )
  
  # Append each session using rbind
  if (i == 1){
    sessionDF <- tempSession
  }
  else {
    sessionDF = rbind(sessionDF, tempSession)
  }
  
  
}


colnames(sessionDF) = c("session_number", "trial_number", "mouse_name", "contrast_left", "contrast_right", "total_number_of_neurons", "number_of_unique_brain_area", "number_of_trials", "contrast_difference", "number_of_active_neurons", "total_number_of_spks", "proportion_of_active_neurons", "firing_rate", "feedback_type")
sessionDF = as.data.frame(sessionDF)
sessionDF$session_number = as.factor(sessionDF$session_number)

datatable(sessionDF)

```

The above data table contains 15 variables. We have some given variables that were described above: mouse_name, contrast_left, contrast_right, and feedback_type. We also have some general variables, session_number and trial_number which tells the session as well as trial within that session that the experiment was run. The remaining variables measure the performance and offers describing features within each trial of each session:

-   total_number_of_neurons: Total number of neurons specific to the session.
-   number_of_unique_brain_area: The number of brain areas that experience neural spikes, unique to the session.
-   number_of_trials: Number of trials/experiments performed during the specific session.
-   contrast_difference: Absolute difference between the left contrast and right contrast.
-   number_of_active_neurons: Total number of neurons that experienced at least one spike during the trial.
-   total_number_of_spks: Total number of spikes that occurred during the trial (some neurons gave off multiple spikes when faced with the visual stimuli).
-   proportion_of_active_neurons: The proportion of neurons that that experienced at least one spike during the trial (number_of_active_neurons / total_number_of_neurons).
-   firing_rate: The rate at which the spikes in the neurons were fired specific to the trial. This is the total number of spikes that were not equal to 0, divided by the total number of spikes.

These variables were used because they provided information that captures differences across trials of general brain activity. It gives a general scope of how neurons in general, and the rate and amount at which they fire spikes can lead to how a mouse may make a decision when faced with the stimuli.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Box plots of firing rate (or numberofactiveneurons, total num of spikes, or proportion) on feedbacktype

# Firing Rate on Feedback Type
firingRate_by_feedback_boxPlot <- ggplot(sessionDF, aes(x = as.factor(feedback_type), y = firing_rate)) + geom_boxplot(outlier.color="red", outlier.shape=8, outlier.size=2, alpha = 0.2) + xlab("Feedback Type") + ylab("Firing Rate") + theme(legend.position="none")

# Number of Active Neurons on Feedback Type
numActiveNeurons_by_feedback_boxPlot <- ggplot(sessionDF, aes(x = as.factor(feedback_type), y = number_of_active_neurons)) + geom_boxplot(outlier.color="red", outlier.shape=8, outlier.size=2, alpha = 0.2) + xlab("Feedback Type") + ylab("Number of Active Neurons") + theme(legend.position="none")

# Total Number of Spikes on Feedback Type
totalNumSpikes_by_feedback_boxPlot <- ggplot(sessionDF, aes(x = as.factor(feedback_type), y = total_number_of_spks)) + geom_boxplot(outlier.color="red", outlier.shape=8, outlier.size=2, alpha = 0.2) + xlab("Feedback Type") + ylab("Total Number of Spikes") + theme(legend.position="none")

# Proportion of Active Neurons on Feedback Type
proportionActiveNeurons_by_feedback_boxPlot <- ggplot(sessionDF, aes(x = as.factor(feedback_type), y = proportion_of_active_neurons)) + geom_boxplot(outlier.color="red", outlier.shape=8, outlier.size=2, alpha = 0.2) + xlab("Feedback Type") + ylab("Proportion of Active Neurons") + theme(legend.position="none")


grid.arrange(firingRate_by_feedback_boxPlot, proportionActiveNeurons_by_feedback_boxPlot, numActiveNeurons_by_feedback_boxPlot, totalNumSpikes_by_feedback_boxPlot, nrow = 2, ncol = 2, top = textGrob(paste("Box Plots of Feedback Type Across Sessions")))


```

The above box plots provide information about the effect the four main describing variables have with the variable that we are trying to predict, feedback_type. The box plot of firing rate against feedback type shows that on average, a firing rate of about 0.03 results in feedback type of -1 and 0.034 results in 1. In the box plot with proportion of active neurons, on average a proportion of 0.029 results in feedback type of -1 and 0.031 results in 1. In the box plot with number of active neurons, on average about 1100 active neurons results in feedback type of -1 and 1200 results in 1. In the box plot with total number of spikes, on average about 1200 total spikes results in feedback type of -1 and 1300 results in 1. For all the box plots, there seem to be many outliers with larger values. Also, a feedback type of -1 seems to have a uniform structure, while a feedback type of 1 seems to have a right skew for variables firing rate and proportion of active neurons.


```{r, echo=FALSE, warning=FALSE,include = FALSE, message=FALSE}

# Correlation Matrices for each Session
for (i in 1:18) {
  
  corrplot.mixed(round(cor(sessionDF[sessionDF$session_number == i, c('contrast_left', 'contrast_right', 'contrast_difference', 'number_of_active_neurons', 'total_number_of_spks', 'proportion_of_active_neurons', 'firing_rate', 'feedback_type')]), 2), title = paste("Correlation Matrix of Session", i), mar=c(1,1,1,1))
  
}
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}

# Correlation Matrices for Each Mouse
mouseNameVector <- c('Cori', 'Forssmann', 'Hench', 'Lederberg')
for (i in 1:length(mouseNameVector)) {
  
  corrplot.mixed(round(cor(sessionDF[sessionDF$mouse_name == mouseNameVector[i], c('contrast_left', 'contrast_right', 'number_of_active_neurons', 'total_number_of_spks', 'proportion_of_active_neurons', 'firing_rate', 'feedback_type')]), 2), title = paste("Correlation Matrix of Mouse", mouseNameVector[i]), mar=c(1,1,1,1))
  
}

```

The above correlation matrices for each mice provide us with information about how the variables interact with each other, specific to each mouse, across all sessions. Mice Cori and Forssmann both have strong positive interactions between variables number_of_active_neurons and total_number_of_spks, and proportion_of_active_neurons and firing_rate. Mice Hench and Lederberg have more strong, positive variable interactions: number_of_active_neurons & total_number_of_spks, number_of_active_neurons & proportion_of_active_neurons, number_of_active_neurons & firing_rate, total_number_of_spks & proportion_of_active_neurons, total_number_of_spks & firing_rate, proportion_of_active_neurons & firing_rate.



```{r, echo=FALSE, warning=FALSE, message=FALSE}

# Plots for variables against trials (for individual session analysis)

sessionsToBePlotted <- c(3, 7) # Can change these numbers to plot scatterplots for different sessions.

for (i in sessionsToBePlotted) {
 
  plot1 <- ggplot(sessionDF[sessionDF$session_number == i,], aes(x = trial_number, y = number_of_active_neurons)) + geom_point() + geom_smooth(formula = y ~ x, method="lm") + ggtitle("Number of Active Neurons x Trials") + labs(y = "Number of Active Neurons", x = "Trials")
  
  plot2 <- ggplot(sessionDF[sessionDF$session_number == i,], aes(x = trial_number, y = total_number_of_spks)) + geom_point() + geom_smooth(formula = y ~ x, method="lm") + ggtitle("Total Number of Spikes x Trials") + labs(y = "Total Number of Spikes", x = "Trials")
  
  plot3 <- ggplot(sessionDF[sessionDF$session_number == i,], aes(x = trial_number, y = proportion_of_active_neurons)) + geom_point() + geom_smooth(formula = y ~ x, method="lm") + ggtitle("Prop of Active Neurons x Trials") + labs(y = "Proportion of Active Neurons", x = "Trials")
  
  plot4 <- ggplot(sessionDF[sessionDF$session_number == i,], aes(x = trial_number, y = firing_rate)) + geom_point() + geom_smooth(formula = y ~ x, method="lm") + ggtitle("Firing Rate x Trials") + labs(y = "Firing Rate", x = "Trials")
  
  grid.arrange(plot1, plot2, plot3, plot4, nrow = 2, ncol = 2, top = textGrob(paste("Session", i, "Scatterplots")))
   
}

```

The above are scatter plots of the four main describing variables plotted against trials for a specific session. We will be looking at two different sessions, session 3 and session 7, so that there are not 18 x 4 different plots (the code provided was constructed to produce all the plots for the 18 different sessions). Throughout the different 18 sessions, different linear associations were seen. These varied from positive to negative, and weak to strong linear associations. Looking session 3, it can be seen that the variables share a negative, semi-strong linear association. But when looking at session 7, there seems to be a positive, semi-strong linear association. It is important to remember that each session contains different variables, which most likely is the reason to why there are different relationships. For example, the mouse Cori was used in session 3 and the mouse Forssmann was used in session 7, and since these mice are different, they may perform differently in experiments.


```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Plots for variables against trials (for session analysis)

ggplot(sessionDF, aes(x = trial_number, y = number_of_active_neurons, colour = session_number)) + geom_point() + geom_smooth(method = "loess", formula = y ~ x) + ggtitle("Scatterplot of Number of Active Neurons Against Trials") + labs(y = "Number of Active Neurons", x = "Trials")

ggplot(sessionDF, aes(x = trial_number, y = total_number_of_spks, colour = session_number)) + geom_point() + geom_smooth(method = "loess", formula = y ~ x) + ggtitle("Scatterplot of Total Number of Spikes Against Trials") + labs(y = "Total Number of Spikes", x = "Trials")

ggplot(sessionDF, aes(x = trial_number, y = proportion_of_active_neurons, colour = session_number)) + geom_point() + geom_smooth(method = "loess", formula = y ~ x)  + ggtitle("Scatterplot of Proportion of Active Neurons Against Trials") + labs(y = "Proportion of Active Neurons", x = "Trials")

ggplot(sessionDF, aes(x = trial_number, y = firing_rate, colour = session_number)) + geom_point() + geom_smooth(method = "loess", formula = y ~ x)  + ggtitle("Scatterplot of Firing Rate Against Trials") + labs(y = "Firing Rate", x = "Trials")


```

Above are scatter plots of the same four main describing variables plotted against trials for all of the sessions. This form of plotting allows for us to view the changes across all of the sessions. From this view, we can see that there are not always simple positive or negative linear relationships, different sessions provide different data. From this graph we can see that the number of active neurons, total number of spikes, proportion of active neurons, and firing rate seem to decrease across trials (except for session 13).


## Data Integration

In order to combine data across all the trials, the K-Means clustering method was used. Three clusters were made using the complete data frame variables except for variables that do not provide much information or that we are wanting to predict: session_number, trial_number, mouse_name, number_of_trials, and feedback_type. This way we could group the shared patterns between all the informing variables, across all trials. Performing K-Means clustering resulted in a vector containing which trials belonged to which cluster. This vector was then appended to the original complete data frame so that this new column could be used in our predictive modeling methods. The updated data frame is shown below, with a new variable cluster_id. This variable takes the values 1-3, identifying which cluster they belong to.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Perform KMeans clustering

sessionDF[is.na(sessionDF)] <- 0

# Clustering data for 3 clusters
sessionDF.k3 <- subset(sessionDF, select = -c(session_number, trial_number, mouse_name, number_of_trials, feedback_type)) %>% kmeans(3)
clusterIndicatorVector <- sessionDF.k3$cluster

# Append the cluster indicator to the dataframes for further analysis
sessionDF <- cbind(clusterIndicatorVector, sessionDF)
colnames(sessionDF)[1] <- "cluster_id"

datatable(sessionDF)

```

## Predictive Modeling

For predictive modeling, three different methods were used: Logistic Regression, Tree-Based Regression, and Support Vector Machine Regression. Before applying these methods, the data was split into training and testing sets by a 80%/20% split. In order to do this split, 1016 numbers were randomly sampled (1016 is 20% of all trials within the data frame) and then the test set was derived from the rows that were at the positions of the 1016 numbers. The remaining were made into the training sets. The training and testing data were then scaled since the variables in the data set vary in numerical size. For the different methods, these were the only variable used to predict feedback type: cluster_id, contrast_left, contrast_right, total_number_of_neurons, number_of_unique_brain_area, contrast_difference, number_of_active_neurons, total_number_of_spks, proportion_of_active_neurons, firing_rate.


```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Apply logistic regression to sessionDF

# First split the data into training and testing groups, 20/80 split
randomSelection <- sample.int(nrow(sessionDF), 1016)
sessionDF_test <- sessionDF[randomSelection, ]
sessionDF_train <- sessionDF[-randomSelection, ]


# Scale the training and testing data
sessionDF_test[,5:14] <- scale(sessionDF_test[,5:14])
sessionDF_test[,1] <- scale(sessionDF_test[,1])

sessionDF_train[,5:14] <- scale(sessionDF_train[,5:14])
sessionDF_train[,1] <- scale(sessionDF_train[,1])
  

# logistic regression on training data
sessionDF.logreg <- glm(as.factor(feedback_type) ~ cluster_id + contrast_left + contrast_right + total_number_of_neurons + number_of_unique_brain_area + contrast_difference + number_of_active_neurons + total_number_of_spks + proportion_of_active_neurons + firing_rate, data = sessionDF_train, family = "binomial")

logRegpredictedModel <- predict(sessionDF.logreg, sessionDF_test, type = "response")

logRegpredictedModel = ifelse(logRegpredictedModel > 0.5, "-1", "1")
logRegpredictedModel <- as.factor(logRegpredictedModel)


logRegpredictedModel.cm <- confusionMatrix(logRegpredictedModel, as.factor(sessionDF_test$feedback_type))
#logRegpredictedModel.cm$table

logRegpredictedModel.cm.precision <- sum(logRegpredictedModel == 1 & sessionDF_test$feedback_type == 1) / sum(logRegpredictedModel == 1)

logRegpredictedModel.cm.recall <- sum(logRegpredictedModel == 1 & sessionDF_test$feedback_type == 1) / sum(sessionDF_test$feedback_type == 1)

logRegpredictedModel.cm.f1 <- 2 * logRegpredictedModel.cm.precision * logRegpredictedModel.cm.recall / (logRegpredictedModel.cm.precision + logRegpredictedModel.cm.recall)


```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Predictive Model using Tree-Based Method

treePredictedModel2 <- tree(as.factor(feedback_type) ~ cluster_id + contrast_left + contrast_right + total_number_of_neurons + number_of_unique_brain_area + contrast_difference + number_of_active_neurons + total_number_of_spks + proportion_of_active_neurons + firing_rate, data = sessionDF_train)


predictedFeedbackType.tree2 <- predict(treePredictedModel2, newdata = sessionDF_test, type = 'class')

treePredictedModel2.cm <- table(sessionDF_test$feedback_type, predictedFeedbackType.tree2)

treePredictedModel2.cm <- confusionMatrix(treePredictedModel2.cm)
#treePredictedModel2.cm$table

treePredictedModel2.cm.precision <- sum(predictedFeedbackType.tree2 == 1 & sessionDF_test$feedback_type == 1) / sum(predictedFeedbackType.tree2 == 1)

treePredictedModel2.cm.recall <- sum(predictedFeedbackType.tree2 == 1 & sessionDF_test$feedback_type == 1) / sum(sessionDF_test$feedback_type == 1)

treePredictedModel2.cm.f1 <- 2 * treePredictedModel2.cm.precision * treePredictedModel2.cm.recall / (treePredictedModel2.cm.precision + treePredictedModel2.cm.recall)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Predictive Model using Support Vector Machine

SVMPredictedModel = svm(formula = as.factor(feedback_type) ~ cluster_id + contrast_left + contrast_right + total_number_of_neurons + number_of_unique_brain_area + contrast_difference + number_of_active_neurons + total_number_of_spks + proportion_of_active_neurons + firing_rate,
                 data = sessionDF_train,
                 type = 'C-classification',
                 kernel = 'linear')

# Predicting the Test set results
predictedFeedbackType.svm = predict(SVMPredictedModel, newdata = sessionDF_test)

# Making the Confusion Matrix
SVMPredictedModel.cm = table(sessionDF_test$feedback_type, predictedFeedbackType.svm)

SVMPredictedModel.cm <- confusionMatrix(SVMPredictedModel.cm)
#SVMPredictedModel.cm$table

SVMPredictedModel.cm.precision <- sum(predictedFeedbackType.svm == 1 & sessionDF_test$feedback_type == 1) / sum(predictedFeedbackType.svm == 1)

SVMPredictedModel.cm.recall <- sum(predictedFeedbackType.svm == 1 & sessionDF_test$feedback_type == 1) / sum(sessionDF_test$feedback_type == 1)

SVMPredictedModel.cm.f1 <- 2 * SVMPredictedModel.cm.precision * SVMPredictedModel.cm.recall / (SVMPredictedModel.cm.precision + SVMPredictedModel.cm.recall)

```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Create table containing the different accuracies and predictive model methods

modelAccuraciesTable <- data.frame(v1 = c(round(logRegpredictedModel.cm$overall['Accuracy'], digits = 3), logRegpredictedModel.cm.precision, logRegpredictedModel.cm.recall, logRegpredictedModel.cm.f1),
                                   v2 = c(round(treePredictedModel2.cm$overall['Accuracy'], digits = 3), treePredictedModel2.cm.precision, treePredictedModel2.cm.recall, treePredictedModel2.cm.f1),
                                   v3 = c(round(SVMPredictedModel.cm$overall['Accuracy'], digits = 3), SVMPredictedModel.cm.precision, SVMPredictedModel.cm.recall, SVMPredictedModel.cm.f1))

modelAccuraciesTable <- data.frame(lapply(modelAccuraciesTable, function(x) if(is.numeric(x)) round(x, 3) else x))

colnames(modelAccuraciesTable) <- c("Logistic", "Tree-Based", "SVM")
rownames(modelAccuraciesTable) <- c("Accuracy", "Precision", "Recall", "F1-Score")

datatable(modelAccuraciesTable)

```

The above table displays the different performance metrics associated with each type of predictive regression method derived from their respective correlation matrix. The precision measures the proportion of correctly predicted feedback = 1 out of all instances predicted as feedback = 1. The recall measures the proportion of correctly predicted feedback = 1 out of all actual feedback = 1. The F1-Score combines both the recall and precision metrics to form a balanced measure of both the false positives and false negatives.

Logistic regression produced the worst accuracy and had the lowest performance overall. This model was only able to correctly predict feedback type about 29% of the time and had very low precision, recall, and F1-Score percentages.

This is the reason why Tree-Based and SVM regression was used, to see if the model could be improved. 

Both SVM and Tree-Based regression performed the same. They had good accuracies of about 71.3%, with high percentages of precision, recall, and F1-Score. These models were able make predictions much better than logistic regression.


## Prediction Performance on Test Sets

Following the release of the test data, the training set it just the complete data frame holding all the recorded trials across all 18 sessions, and the test set is the set provided to us.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Load the session test data information

sessionTestData=list()
for(i in 1:2){
  sessionTestData[[i]]=readRDS(paste('./Data/test',i,'.rds',sep=''))
  
}

testDataFrame <- data.frame()

for (i in 1:2) {

  #Create a custom dataframe here with 4 columns for 4 variables
  trialDF <- data.frame(matrix(ncol = 5, nrow = 0))

  for (j in 1:length(sessionTestData[[i]]$spks)) { 
    
    # Calculate the total number of neurons active
    neuronCountTable = table(unlist(sessionTestData[[i]]$spks[[j]]))
    neuronCountValues = as.numeric(neuronCountTable)
    numActiveNeurons = length(sessionTestData[[i]]$spks[[j]]) - neuronCountValues[1] #neuronCountValues[1] is the # of 0's
    
    # Calculate the total number of spks
    numSpks = 0
    for(k in 1:length(neuronCountTable)) {
    
      numSpks = numSpks + ((k-1) * neuronCountValues[k])
      
    }
    
    # Calculate the proportion of active neurons
    activeNeuronProp = numActiveNeurons / length(sessionTestData[[i]]$spks[[i]])
    
    # Calculate the firing rate (total number of spks != 0 divided by total)
    firing_rate = numSpks / (numSpks + neuronCountValues[1])
    
    # Calculate the absolute difference between left and right contrast
    contrastDifference = abs(sessionTestData[[i]]$contrast_left[j] - sessionTestData[[i]]$contrast_right[j])
    
    # Append to the variables to the trial data frame
    trialDF[nrow(trialDF) + 1,] = c(contrastDifference, numActiveNeurons, numSpks, activeNeuronProp, firing_rate)
    
  }
  
  # Append data together using cbind
  tempSession = cbind(rep(i,length(sessionTestData[[i]]$contrast_left)),
                       seq(1, length(sessionTestData[[i]]$spks)),
                       sessionTestData[[i]]$mouse_name, 
                       sessionTestData[[i]]$contrast_left,
                       sessionTestData[[i]]$contrast_right,
                       length(sessionTestData[[i]]$brain_area),
                       length(unique(sessionTestData[[i]]$brain_area)),
                       length(sessionTestData[[i]]$spks),
                       trialDF,
                       sessionTestData[[i]]$feedback_type
                       )
  
  # Append each session using rbind
  if (i == 1){
    testDataFrame <- tempSession
  }
  else {
    testDataFrame = rbind(testDataFrame, tempSession)
  }
  
  
}


colnames(testDataFrame) = c("session_number", "trial_number", "mouse_name", "contrast_left", "contrast_right", "total_number_of_neurons", "number_of_unique_brain_area", "number_of_trials", "contrast_difference", "number_of_active_neurons", "total_number_of_spks", "proportion_of_active_neurons", "firing_rate", "feedback_type")
testDataFrame = as.data.frame(testDataFrame)
testDataFrame$session_number = as.factor(testDataFrame$session_number)

# Perform KMeans clustering

testDataFrame[is.na(testDataFrame)] <- 0

# Clustering data for 3 clusters
testDataFrame.k3 <- subset(testDataFrame, select = -c(session_number, trial_number, mouse_name, number_of_trials, feedback_type)) %>% kmeans(3)
clusterIndicatorVector <- testDataFrame.k3$cluster

# Append the cluster indicator to the dataframes for further analysis
testDataFrame <- cbind(clusterIndicatorVector, testDataFrame)
colnames(testDataFrame)[1] <- "cluster_id"

#datatable(testDataFrame)


# Scale the training and testing data
sessionDF.traindata <- sessionDF
sessionDF.traindata[,5:14] <- scale(sessionDF.traindata[,5:14])
sessionDF.traindata[,1] <- scale(sessionDF.traindata[,1])

testDataFrame[,5:14] <- scale(testDataFrame[,5:14])
testDataFrame[,1] <- scale(testDataFrame[,1])
testDataFrame[is.na(testDataFrame)] <- 0

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}

SVMPredictedModel.testdata = svm(formula = as.factor(feedback_type) ~ cluster_id + contrast_left + contrast_right + total_number_of_neurons + number_of_unique_brain_area + contrast_difference + number_of_active_neurons + total_number_of_spks + proportion_of_active_neurons + firing_rate,
                 data = sessionDF.traindata,
                 type = 'C-classification',
                 kernel = 'linear')

# Predicting the Test set results
predictedFeedbackType.svm.testdata = predict(SVMPredictedModel.testdata, newdata = testDataFrame)

# Making the Confusion Matrix
SVMPredictedModel.cm.testdata = table(testDataFrame$feedback_type, predictedFeedbackType.svm.testdata)

SVMPredictedModel.cm.testdata <- confusionMatrix(SVMPredictedModel.cm.testdata)

SVMPredictedModel.cm.testdata.precision <- sum(predictedFeedbackType.svm.testdata == 1 & testDataFrame$feedback_type == 1) / sum(predictedFeedbackType.svm.testdata == 1)

SVMPredictedModel.cm.testdata.recall <- sum(predictedFeedbackType.svm.testdata == 1 & testDataFrame$feedback_type == 1) / sum(testDataFrame$feedback_type == 1)

SVMPredictedModel.cm.testdata.f1 <- 2 * SVMPredictedModel.cm.testdata.precision * SVMPredictedModel.cm.testdata.recall / (SVMPredictedModel.cm.testdata.precision + SVMPredictedModel.cm.testdata.recall)


testDataPerformance <- data.frame(v1 = c(SVMPredictedModel.cm.testdata$overall['Accuracy'], SVMPredictedModel.cm.testdata.precision, SVMPredictedModel.cm.testdata.recall, SVMPredictedModel.cm.testdata.f1))

testDataPerformance <- data.frame(lapply(testDataPerformance, function(x) if(is.numeric(x)) round(x, 3) else x))

colnames(testDataPerformance) <- c("SVM")
rownames(testDataPerformance) <- c("Accuracy", "Precision", "Recall", "F1-Score")

datatable(testDataPerformance)

```

The above table holds the performance metrics associated with the Support Vector Machine Predictive Regression Method. SVM or Tree-Based method could have been used since they performed better than the Logistic method. This predictive model was able to accurately predict the feedback type correctly 72.5% of the time, performing almost the same as how it did when the training and testing data were split using the 80/20 method. This is a realistic predictive model.

## Conclusion/Discussion

The primary objective was to build a model that can predict the feedback type of a mouse, at each trial, using the neural activity data and contrasts. This was able to be done after using clustering and classification techniques. A logistic regression predictive model was not able to accurately predict the feedback type given the variables that were provided and derived from the data. This led to the usage of a Support Vector Machine and Tree-Based predictive model, which performed very similarly to each other, and was able to predict the feedback type correctly about 71.3% of the time. These two models were the best at classification in the scope of this project and mice neural activities. When predicting using the provided test data, the SVM model was able to correctl predict the feedback type 72.5% of th time.

Some drawbacks and disadvantages of these predictive models were the variables that were used. While these variables were able to capture information specific to the trial's neural activity, they were not able to bring information about the specific brain areas that were being activated. Certain brain areas are responsible for a mouse triggering actions, or making decisions. If one could completely understand which brain areas are responsible for which thoughts, deriving variables around brain area firing rates could possibly provide a more accurate prediction model.

Moving forward, future studies should incorporate a way to include patterns of brain areas, understanding which brain areas had spikes can be key in determining what makes a mouse make these decisions. The brain of the mouse and the different areas need to be studied so that one can understand which areas are responsible for which thoughts or actions. This would allow for predictive models in the future to be able to mimic an actual mouse brain's decision choice when faced with visual stimuli.


------------------------------------------------------------------------

## Reference

Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x

------------------------------------------------------------------------

## Appendix {.unnumbered}

```{=tex}
\begin{center} Appendix: R Script \end{center}
```
```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```

## Session Info

```{r}
sessionInfo()
```